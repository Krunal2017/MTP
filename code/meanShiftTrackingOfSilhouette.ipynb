{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import scipy.io\n",
    "# from sklearn.svm import SVC\n",
    "import skvideo.io\n",
    "from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import Isomap\n",
    "# from sklearn.manifold import LocallyLinearEmbedding\n",
    "from scipy.ndimage import morphology as mp\n",
    "from skimage.feature import canny\n",
    "from thundersvm import SVC\n",
    "from random import sample\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction import image\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mahotas\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import os\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playVideo(file):\n",
    "    (major, minor) = cv2.__version__.split(\".\")[:2]\n",
    "\n",
    "    OPENCV_OBJECT_TRACKERS = {\n",
    "        \"csrt\": cv2.TrackerCSRT_create,\n",
    "        \"kcf\": cv2.TrackerKCF_create,\n",
    "        \"boosting\": cv2.TrackerBoosting_create,\n",
    "        \"mil\": cv2.TrackerMIL_create,\n",
    "        \"tld\": cv2.TrackerTLD_create,\n",
    "        \"medianflow\": cv2.TrackerMedianFlow_create,\n",
    "        \"mosse\": cv2.TrackerMOSSE_create\n",
    "    }\n",
    "\n",
    "    # grab the appropriate object tracker using our dictionary of\n",
    "    # OpenCV object tracker objects\n",
    "    tracker = OPENCV_OBJECT_TRACKERS[\"kcf\"]()\n",
    "\n",
    "    vs = cv2.VideoCapture(file)\n",
    "    initBB = None\n",
    "    # initialize the FPS throughput estimator\n",
    "    fps = None\n",
    "    \n",
    "    boxes = {}\n",
    "    \n",
    "    # loop over frames from the video stream\n",
    "    fno = 1\n",
    "    delay=1\n",
    "    while True:\n",
    "        # grab the current frame, then handle if we are using a\n",
    "        # VideoStream or VideoCapture object\n",
    "        frame1 = vs.read()\n",
    "        frame = frame1[1] # if args.get(\"video\", False) else frame1\n",
    "        # frame = fgbg.apply(frame)\n",
    "\n",
    "        # check to see if we have reached the end of the stream\n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "        # resize the frame (so we can process it faster) and grab the\n",
    "        # frame dimensions\n",
    "        frame = imutils.resize(frame, width=500)\n",
    "        (H, W) = frame.shape[:2]\n",
    "\n",
    "        # check to see if we are currently tracking an object\n",
    "        if initBB is not None:\n",
    "            # grab the new bounding box coordinates of the object\n",
    "            (success, box) = tracker.update(frame)\n",
    "\n",
    "            # check to see if the tracking was a success\n",
    "            if success:\n",
    "                (x, y, w, h) = [int(v) for v in box]\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h),\n",
    "                    (0, 255, 0), 2)\n",
    "                boxes[fno]=[x,y,x+w,y+h]\n",
    "\n",
    "            # update the FPS counter\n",
    "            if fps is not None:\n",
    "                fps.update()\n",
    "                fps.stop()\n",
    "\n",
    "                # initialize the set of information we'll be displaying on\n",
    "                # the frame\n",
    "                info = [\n",
    "                    (\"Tracker\", \"kcf\"),\n",
    "                    (\"Success\", \"Yes\" if success else \"No\"),\n",
    "                    (\"FPS\", \"{:.2f}\".format(fps.fps())),\n",
    "                ]\n",
    "                \n",
    "                if success:\n",
    "                    delay=5\n",
    "                else:\n",
    "                    delay=10\n",
    "\n",
    "                # loop over the info tuples and draw them on our frame\n",
    "                for (i, (k, v)) in enumerate(info):\n",
    "                    text = \"{}: {}\".format(k, v)\n",
    "                    cv2.putText(frame, text, (10, H - ((i * 20) + 20)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        else:\n",
    "            initBB = cv2.selectROI(\"Frame\", frame, fromCenter=False,\n",
    "                showCrosshair=True)\n",
    "            print(\"Initial BBox: \"+str(initBB))\n",
    "\n",
    "            # start OpenCV object tracker using the supplied bounding box\n",
    "            # coordinates, then start the FPS throughput estimator as well\n",
    "            tracker.init(frame, initBB)\n",
    "            fps = FPS().start()\n",
    "        # show the output frame\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(10) & 0xFF\n",
    "\n",
    "        # if the 's' key is selected, we are going to \"select\" a bounding\n",
    "        # box to track\n",
    "        if key == ord(\"s\"):\n",
    "            # select the bounding box of the object we want to track (make\n",
    "            # sure you press ENTER or SPACE after selecting the ROI)\n",
    "            tracker = OPENCV_OBJECT_TRACKERS[\"kcf\"]()\n",
    "            initBB = None\n",
    "            # initialize the FPS throughput estimator\n",
    "            fps = None\n",
    "            initBB = cv2.selectROI(\"Frame\", frame, fromCenter=False,\n",
    "                showCrosshair=True)\n",
    "            print(\"Frame: \"+str(fno)+\" Selected BBox: \"+str(initBB))\n",
    "\n",
    "            # start OpenCV object tracker using the supplied bounding box\n",
    "            # coordinates, then start the FPS throughput estimator as well\n",
    "            tracker.init(frame, initBB)\n",
    "            fps = FPS().start()\n",
    "\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "        elif key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "        fno=fno+1\n",
    "\n",
    "    #         # if we are using a webcam, release the pointer\n",
    "    #         if not args.get(\"video\", False):\n",
    "    #             vs.stop()\n",
    "\n",
    "    #         # otherwise, release the file pointer\n",
    "    #         else:\n",
    "\n",
    "    vs.release()\n",
    "\n",
    "    # close all windows\n",
    "    cv2.destroyAllWindows()\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showBBoxes(file,boxes,label):\n",
    "    vs = cv2.VideoCapture(file)\n",
    "    \n",
    "    # loop over frames from the video stream\n",
    "    fno = 1\n",
    "    \n",
    "    while True:\n",
    "        # grab the current frame, then handle if we are using a\n",
    "        # VideoStream or VideoCapture object\n",
    "        frame1 = vs.read()\n",
    "        frame = frame1[1] # if args.get(\"video\", False) else frame1\n",
    "        # frame = fgbg.apply(frame)\n",
    "\n",
    "        # check to see if we have reached the end of the stream\n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "        # resize the frame (so we can process it faster) and grab the\n",
    "        # frame dimensions\n",
    "        frame = imutils.resize(frame, width=500)\n",
    "        (H, W) = frame.shape[:2]\n",
    "\n",
    "        # check to see if we are currently tracking an object\n",
    "        if fno in boxes:\n",
    "            (x1,y1,x2,y2) = boxes[fno]\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2),\n",
    "                        (0, 255, 0), 2)\n",
    "\n",
    "        # show the output frame\n",
    "        cv2.imshow(\"Class: \"+str(label), frame)\n",
    "        key = cv2.waitKey(20) & 0xFF\n",
    "\n",
    "#         # if the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "        fno=fno+1\n",
    "\n",
    "    vs.release()\n",
    "\n",
    "    # close all windows\n",
    "    cv2.destroyAllWindows()\n",
    "#     data={'X':X,'Y':Y}\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Show BBoxes ############################\n",
    "basePath = \"../IndianBirds/\"\n",
    "\n",
    "for i in range(9,10):\n",
    "    boxes = {}\n",
    "    fullPath = basePath+str(i)+\"/\"\n",
    "    allfiles = os.listdir(fullPath)\n",
    "    if not allfiles:\n",
    "        continue\n",
    "    f = open(fullPath+\"bbox.pkl\",\"rb\")\n",
    "#     f = open(fullPath+\"bbox.pkl\",\"rb\")\n",
    "    boxes=pickle.load(f)\n",
    "    f.close()\n",
    "    j=0;\n",
    "#     for j in range(2):\n",
    "#     for j in range(len(allfiles)):\n",
    "#         file = allfiles[j];\n",
    "#     box = boxes[allfiles[0]][221]\n",
    "    for file in allfiles:\n",
    "        if file.endswith(\".mp4\"):\n",
    "            showBBoxes(fullPath+file,boxes[file],i)\n",
    "            j=j+1\n",
    "        if (j==2):\n",
    "            break\n",
    "#         boxes[file] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc=SVC()\n",
    "svc.load_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Track silhouette ###########################\n",
    "def trackSilhouette(file,boxes,label):\n",
    "    vs = cv2.VideoCapture(file)\n",
    "    \n",
    "    # loop over frames from the video stream\n",
    "    fno = 1\n",
    "    x11,x22,y11,y22 = 0,0,0,0\n",
    "    track = False\n",
    "        # set up the ROI for tracking\n",
    "    roi = None\n",
    "    hsv_roi =  None\n",
    "    mask = None\n",
    "    roi_hist = None\n",
    "    # cv.normalize(roi_hist,roi_hist,0,255,cv.NORM_MINMAX)\n",
    "    # Setup the termination criteria, either 10 iteration or move by atleast 1 pt\n",
    "    term_crit = None\n",
    "    \n",
    "    while True:\n",
    "        # grab the current frame, then handle if we are using a\n",
    "        # VideoStream or VideoCapture object\n",
    "        frame1 = vs.read()\n",
    "        frame = frame1[1] # if args.get(\"video\", False) else frame1\n",
    "        # frame = fgbg.apply(frame)\n",
    "\n",
    "        # check to see if we have reached the end of the stream\n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "        # resize the frame (so we can process it faster) and grab the\n",
    "        # frame dimensions\n",
    "        frame = imutils.resize(frame, width=500)\n",
    "        (H, W) = frame.shape[:2]\n",
    "\n",
    "        # check to see if we are currently tracking an object\n",
    "        if fno in boxes:\n",
    "            (x1,y1,x2,y2) = boxes[fno]\n",
    "            cropped_im = frame[y1:y2,x1:x2]\n",
    "            if(track == True):\n",
    "                hsv = cv2.cvtColor(cropped_im, cv2.COLOR_BGR2HSV)\n",
    "                dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "                # apply meanshift to get the new location\n",
    "                # print(track_window)\n",
    "                ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "                # Draw it on image\n",
    "                x11,y11,w,h = track_window\n",
    "                cv2.rectangle(cropped_im, (x11, y11), (x11+w, y11+h),\n",
    "                        (0, 255, 0), 2)\n",
    "\n",
    "            # show the output frame\n",
    "            cv2.imshow(\"Class: \"+str(label), cropped_im)\n",
    "            if(track == False):\n",
    "                next_img = predictSilhouette2(cropped_im)\n",
    "                sil_gray = cv2.cvtColor(next_img, cv2.COLOR_BGR2GRAY)\n",
    "                i1, j1 = np.where(sil_gray)\n",
    "                track = True\n",
    "                indices = np.meshgrid(np.arange(min(i1), max(i1) + 1),\n",
    "                                      np.arange(min(j1), max(j1) + 1),\n",
    "                                      indexing='ij')\n",
    "                x11,y11 = indices[0][0,0],indices[1][0,0]\n",
    "                x22,y22 = indices[0][indices[0].shape[0]-1,indices[0].shape[1]-1],indices[1][indices[1].shape[0]-1,indices[1].shape[1]-1]\n",
    "                track = True\n",
    "                track_window = (x11,y11,x22,y22)\n",
    "#                 tracker.init(cropped_im, track_window)\n",
    "#                 print(initBB)\n",
    "#                 print('--')\n",
    "#                 print(track_window)\n",
    "                roi = next_img\n",
    "                hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "                hsv_im =  cv2.cvtColor(cropped_im, cv2.COLOR_BGR2HSV)\n",
    "                mask = cv2.inRange(hsv_roi, np.array((0., 0.,0.)), np.array((255.,255.,255.)))\n",
    "                roi_hist = cv2.calcHist([hsv_im],[0],mask,[180],[0,180])\n",
    "                cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "                # Setup the termination criteria, either 10 iteration or move by atleast 1 pt\n",
    "                term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 100, 1 )\n",
    "#                     sub_image = cropped_im[indices]\n",
    "        key = cv2.waitKey(20) & 0xFF\n",
    "\n",
    "#         # if the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "        fno=fno+1\n",
    "\n",
    "    vs.release()\n",
    "\n",
    "    # close all windows\n",
    "    cv2.destroyAllWindows()\n",
    "#     data={'X':X,'Y':Y}\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# Method for testing with Strides ###################################\n",
    "def predictSilhouette2(next_img):\n",
    "#     x1,y1,x2,y2 = box\n",
    "    i=0;\n",
    "    TEST1=None\n",
    "    psize=8\n",
    "    svc = SVC()\n",
    "    svc.load_from_file(\"training/9/class9_svc.pkl\")\n",
    "    # psize=4\n",
    "    [m,n,p] = next_img.shape\n",
    "    while i<(m-psize):\n",
    "        j=0;\n",
    "        while j<(n-psize):\n",
    "            a = copy.copy(next_img[i:i+psize,j:j+psize])\n",
    "            a = a.flatten()\n",
    "            if TEST1 is None:\n",
    "                TEST1 = a\n",
    "            else:\n",
    "                TEST1 = np.vstack([TEST1,a])\n",
    "            j=j+int(psize/2)\n",
    "        i=i+int(psize/2)\n",
    "\n",
    "    predictions = svc.predict(TEST1)\n",
    "\n",
    "    i=0;\n",
    "    k=0;\n",
    "    [m,n,p] = next_img.shape\n",
    "    new_mask = np.zeros([m,n,p])\n",
    "    count = np.zeros([m,n,p])\n",
    "    while i<(m-psize):\n",
    "        j=0;\n",
    "        while j<(n-psize):\n",
    "            if k < len(predictions):\n",
    "                if(predictions[k]==1):\n",
    "                    new_mask[i:i+psize,j:j+psize] = new_mask[i:i+psize,j:j+psize] + 1\n",
    "                    count[i:i+psize,j:j+psize] = count[i:i+psize,j:j+psize] + 1\n",
    "                k = k+1\n",
    "            j=j+int(psize/2)\n",
    "        i=i+int(psize/2)\n",
    "\n",
    "    count [count==0] = 1\n",
    "    reconstructed1 = []\n",
    "    reconstructed1 = new_mask/count\n",
    "    ret,thresh1 = cv2.threshold(reconstructed1,0.7,1,cv2.THRESH_BINARY)\n",
    "    print(\"Thresholded Mask:\");\n",
    "#     plt.imshow(thresh1),plt.show();\n",
    "\n",
    "#     mask1 = reconstructed1.astype(np.bool)\n",
    "    mask1 = thresh1.astype(np.bool)\n",
    "    silhouette1 = np.zeros_like(next_img)\n",
    "    silhouette1[mask1] = next_img[mask1]\n",
    "    print(\"Thresholded Silhouette:\");\n",
    "#     plt.imshow(silhouette1),plt.show();\n",
    "\n",
    "    gray_sil = cv2.cvtColor(silhouette1, cv2.COLOR_BGR2GRAY)\n",
    "    connected_mask = undesired_objects(gray_sil)\n",
    "    \n",
    "    stacked_img = np.stack((connected_mask,)*3, axis=-1)\n",
    "    \n",
    "#     plt.imshow(stacked_img),plt.show();\n",
    "    \n",
    "    mask = stacked_img.astype(np.bool)\n",
    "    silhouette = np.zeros_like(next_img)\n",
    "    silhouette[mask] = next_img[mask]\n",
    "#     cv2.rectangle(silhouette, (x1, y1), (x2, y2),\n",
    "#                         (0, 255, 0), 2)\n",
    "#     cv2.imshow(\"Frame:\",silhouette);\n",
    "#     plt.imshow(silhouette),plt.show();\n",
    "    \n",
    "#     edges = canny(connected_mask)\n",
    "#     fill_holes = mp.binary_fill_holes(edges)\n",
    "\n",
    "#     stacked_img = np.stack((fill_holes,)*3, axis=-1)\n",
    "#     stacked_img = stacked_img.astype(float)\n",
    "#     # type(stacked_img)\n",
    "# #     print(\"Filled Mask:\");\n",
    "# #     plt.imshow(stacked_img),plt.show();\n",
    "\n",
    "#     mask2 = stacked_img.astype(np.bool)\n",
    "#     silhouette2 = np.zeros_like(next_img)\n",
    "#     silhouette2[mask2] = next_img[mask2]\n",
    "# #     print(\"Filled Silhouette:\");\n",
    "#     plt.imshow(silhouette2),plt.show();\n",
    "    \n",
    "    return silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undesired_objects (image):\n",
    "    image = image.astype('uint8')\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(image, connectivity=4)\n",
    "    sizes = stats[:, -1]\n",
    "\n",
    "    max_label = 1\n",
    "    max_size = sizes[1]\n",
    "    for i in range(2, nb_components):\n",
    "        if sizes[i] > max_size:\n",
    "            max_label = i\n",
    "            max_size = sizes[i]\n",
    "\n",
    "#     img2 = np.zeros(output.shape)\n",
    "#     img2[output == max_label] = 255\n",
    "#     plt.imshow(img2),plt.show();\n",
    "    img2 = np.zeros(output.shape)\n",
    "    img2[output == max_label] = 1\n",
    "    return img2\n",
    "#     cv2.imshow(\"Biggest component\", img2)\n",
    "#     cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholded Mask:\n",
      "Thresholded Silhouette:\n"
     ]
    }
   ],
   "source": [
    "########################### Show BBoxes ############################\n",
    "basePath = \"../IndianBirds/\"\n",
    "\n",
    "for i in range(9,10):\n",
    "    boxes = {}\n",
    "    fullPath = basePath+str(i)+\"/\"\n",
    "    allfiles = os.listdir(fullPath)\n",
    "    if not allfiles:\n",
    "        continue\n",
    "    f = open(fullPath+\"bbox.pkl\",\"rb\")\n",
    "#     f = open(fullPath+\"bbox.pkl\",\"rb\")\n",
    "    boxes=pickle.load(f)\n",
    "    f.close()\n",
    "    j=0;\n",
    "#     for j in range(2):\n",
    "#     for j in range(len(allfiles)):\n",
    "#         file = allfiles[j];\n",
    "#     box = boxes[allfiles[0]][221]\n",
    "    for file in allfiles:\n",
    "        if file.endswith(\".mp4\"):\n",
    "            trackSilhouette(fullPath+file,boxes[file],i)\n",
    "            j=j+1\n",
    "        if (j==1):\n",
    "            break\n",
    "#         boxes[file] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
